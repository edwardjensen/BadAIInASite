# Bad AI In A Site - Environment Configuration
# Copy this file to .env and fill in your actual values

# Server Configuration
PORT=3000
NODE_ENV=development

# LM Studio Configuration
# IP address or hostname of your LM Studio server
LM_STUDIO_ADDRESS=localhost

# Alternative: You can also set the full URL directly (overrides LM_STUDIO_ADDRESS)
# LM_STUDIO_URL=http://localhost:1234/v1/chat/completions

# OpenRouter API Configuration
# Get your API key from https://openrouter.ai/
# It's safe to put your real API key in the .env file (not tracked by git)
OPENROUTER_API_KEY=your-openrouter-api-key-here

# AI Model Configuration
# Default model to use with LM Studio (optional, defaults to 'local-model')
# DEFAULT_LMSTUDIO_MODEL=deepseek-r1-distill-llama-8b

# Default model to use with OpenRouter (optional, defaults to 'google/gemini-2.0-flash-exp:free')
# DEFAULT_OPENROUTER_MODEL=google/gemini-2.0-flash-exp:free